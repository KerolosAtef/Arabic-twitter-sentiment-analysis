{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Check the availbility of GPU"
   ],
   "metadata": {
    "id": "sknaEID8BGWd",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(len(tf.config.list_physical_devices('GPU')))\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JoULgUdDj4SA",
    "outputId": "f6b64868-96d0-40a1-a02b-8801b08de5bd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download datasets"
   ],
   "metadata": {
    "id": "eLlcFzgHlhFW",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown --id 1SRB7w6x_6oVUOzJihlYA5T2VR8u0UJyd\n",
    "!gdown --id 1zs91kg3MO6FNkmtHFo1bqOF2Iy1F1b4y\n",
    "!gdown --id 165kzfZDsRTZAAfZKedeZiUlKzMcHNgPd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ID2bvGilgSU",
    "outputId": "608c0304-b030-4db5-80e8-902cb3087b8b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1SRB7w6x_6oVUOzJihlYA5T2VR8u0UJyd\n",
      "To: /content/Twitter_train.csv\n",
      "100% 261k/261k [00:00<00:00, 122MB/s]\n",
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zs91kg3MO6FNkmtHFo1bqOF2Iy1F1b4y\n",
      "To: /content/Twitter_test.csv\n",
      "100% 84.4k/84.4k [00:00<00:00, 84.1MB/s]\n",
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=165kzfZDsRTZAAfZKedeZiUlKzMcHNgPd\n",
      "To: /content/Arabic_stop_words.txt\n",
      "100% 6.48k/6.48k [00:00<00:00, 8.89MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pyarabic"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L77LFKMYkJZg",
    "outputId": "fd410e8f-7233-412f-83ea-82c19f76e8a4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyarabic\n",
      "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
      "\u001B[K     |████████████████████████████████| 126 kB 11.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic) (1.15.0)\n",
      "Installing collected packages: pyarabic\n",
      "Successfully installed pyarabic-0.6.15\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pyarabic.araby as ar\n",
    "\n",
    "# import Stemmer\n",
    "import functools, operator\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logger = logging.getLogger(__name__)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "xDZ08i40j4SH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "Y-BpP8TZugwK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Twitter_train.csv\")\n",
    "seed=42"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "b90o2vElugwT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arabic stop words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "Zr_8LPo0ugwX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lJ0o2qs7ugwZ"
   },
   "outputs": [],
   "source": [
    "arabic_stop_words=[]\n",
    "with open ('Arabic_stop_words.txt',encoding='utf-8') as f :\n",
    "  for i in f.readlines() :\n",
    "    arabic_stop_words.append(i)\n",
    "    arabic_stop_words[-1]=arabic_stop_words[-1][:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting farasapy\n",
      "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy) (4.64.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (3.0.4)\n",
      "Installing collected packages: farasapy\n",
      "Successfully installed farasapy-0.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install farasapy"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETdZlcCHj4SM",
    "outputId": "daac8d2c-3063-4909-e738-cc660bf6a67b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#============= Read CSV and apply data preperation =============#\n",
    "\n",
    "\n",
    "def data_preprocessing (data_frame):\n",
    "  # clean-up: remove #tags, http links and special symbols\n",
    "  data_frame['tweet']= data_frame['tweet'].apply(lambda x: x[2:-2])\n",
    "  data_frame['tweet']= data_frame['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "  data_frame['tweet'] = data_frame['tweet'].apply(lambda x: re.sub(r'[@|#]\\S*', '', x))\n",
    "  data_frame['tweet'] = data_frame['tweet'].apply(lambda x: re.sub(r'\"+', '', x))\n",
    "\n",
    "  # Remove arabic signs\n",
    "  data_frame['tweet'] = data_frame['tweet'].apply(lambda x: re.sub(r'([@A-Za-z0-9_ـــــــــــــ]+)|[^\\w\\s]|#|http\\S+', '', x))\n",
    "\n",
    "  # Remove repeated letters like \"الللللللللللللللله\" to \"الله\"\n",
    "  data_frame['tweet'] = data_frame['tweet'].apply(lambda x: x[0:2] + ''.join([x[i] for i in range(2, len(x)) if x[i]!=x[i-1] or x[i]!=x[i-2]]))\n",
    "\n",
    "  # remove stop words\n",
    "  data_frame['tweet'] = data_frame['tweet'].apply(lambda x: '' if x in arabic_stop_words else x)\n",
    "\n",
    "  from nltk.stem.isri import ISRIStemmer\n",
    "  df['tweet']=df['tweet'].apply(lambda x:ISRIStemmer().stem(x))\n",
    "\n",
    "  return data_frame\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "O7VPzTXYugwo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install emoji"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOe29KXMmh1B",
    "outputId": "394b9a69-af09-4817-90d3-d885b253ada8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# st =  Stemmer.Stemmer('arabic')\n",
    "import string,emoji\n",
    "def data_cleaning (text):\n",
    "  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "  text = re.sub(r'^http?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "  text = re.sub(r\"http\\S+\", \"\", text)\n",
    "  text = re.sub(r\"https\\S+\", \"\", text)\n",
    "  text = re.sub(r'\\s+', ' ', text)\n",
    "  text = re.sub(\"(\\s\\d+)\",\"\",text)\n",
    "  text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", \"\", text)\n",
    "  text = re.sub(\"\\d+\", \" \", text)\n",
    "  text = ar.strip_tashkeel(text)\n",
    "  text = ar.strip_tatweel(text)\n",
    "  text = text.replace(\"#\", \" \");\n",
    "  text = text.replace(\"@\", \" \");\n",
    "  text = text.replace(\"_\", \" \");\n",
    "  translator = str.maketrans('', '', string.punctuation)\n",
    "  text = text.translate(translator)\n",
    "  em = text\n",
    "  em_split_emoji = emoji.get_emoji_regexp().split(em)\n",
    "  em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "  em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "  text = \" \".join(em_split)\n",
    "  text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "  # text_stem = \" \".join([st.stemWord(i) for i in text.split()])\n",
    "  # text = text +\" \"+ text_stem\n",
    "  text = text.replace(\"آ\", \"ا\")\n",
    "  text = text.replace(\"إ\", \"ا\")\n",
    "  text = text.replace(\"أ\", \"ا\")\n",
    "  text = text.replace(\"ؤ\", \"و\")\n",
    "  text = text.replace(\"ئ\", \"ي\")\n",
    "\n",
    "  return text"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "WSAZBzasj4SO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df['tweet']=df['tweet'].apply(lambda x: data_cleaning(x))\n",
    "df=data_preprocessing(df)\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "v_gDzrkBwMz6",
    "outputId": "35dc1e8a-bd77-4b7a-9501-c2ca97a0ed67",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  tweet class\n",
       "0     ان الذين يعيشون على الارض ليسوا ملايكة بل بشر ...   pos\n",
       "1                                    كل سنة وانتم طيبين   pos\n",
       "2                                 و انتهى مشوار الخواجة   neg\n",
       "3                             مش عارف ابتدى مذاكره منين   neg\n",
       "4     اختصروا الطريق بدلا من اختيار المنصف ثم الانقل...   neg\n",
       "...                                                 ...   ...\n",
       "2054  الجمال مبيحتاح اي مكياج لناعم وله خشن جمل الطا...   neu\n",
       "2055  نتمني وجود الفنانة رنا سماحة افضل فنانة صاعدة ...   neu\n",
       "2056  ولد الهدى فالكاينات ضياء وفم الزمان تبسم وسناء...   pos\n",
       "2057                             انت متناقض جدا يا صلاح   neg\n",
       "2058     منطقة السيدة زينب ليلة المولد مسجد السيدة زينب   neu\n",
       "\n",
       "[2059 rows x 2 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-fe4eb34c-fc30-4959-a647-8e687d995652\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ان الذين يعيشون على الارض ليسوا ملايكة بل بشر ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>كل سنة وانتم طيبين</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>و انتهى مشوار الخواجة</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مش عارف ابتدى مذاكره منين</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اختصروا الطريق بدلا من اختيار المنصف ثم الانقل...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>الجمال مبيحتاح اي مكياج لناعم وله خشن جمل الطا...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>نتمني وجود الفنانة رنا سماحة افضل فنانة صاعدة ...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>ولد الهدى فالكاينات ضياء وفم الزمان تبسم وسناء...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>انت متناقض جدا يا صلاح</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>منطقة السيدة زينب ليلة المولد مسجد السيدة زينب</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2059 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe4eb34c-fc30-4959-a647-8e687d995652')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fe4eb34c-fc30-4959-a647-8e687d995652 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fe4eb34c-fc30-4959-a647-8e687d995652');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fatal: destination path 'arabert' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/aub-mind/arabert.git"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyaQC-Axj4SQ",
    "outputId": "42c6c351-0166-4a30-ee3c-e91c49e8bb4b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "model_name = \"aubmindlab/bert-large-arabertv02-twitter\"\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "\n",
    "df['tweet']=df['tweet'].apply(lambda x: arabert_prep.preprocess(x))\n",
    "\n",
    "\n",
    "# text = \"ولن نبالغ إذا قلنا: إن 'هاتف' أو 'كمبيوتر المكتب' في زمننا هذا ضروري\"\n",
    "# arabert_prep.preprocess(text)\n",
    "# # \"و+ لن نبالغ إذا قل +نا : إن ' هاتف ' أو ' كمبيوتر ال+ مكتب ' في زمن +نا هذا ضروري\""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "omMDhuNzj4SR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "tBEVTgBRugws"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  tweet  class\n",
       "0     ان الذين يعيشون على الارض ليسوا ملايكة بل بشر ...      2\n",
       "1                                    كل سنة وانتم طيبين      2\n",
       "2                                 و انتهى مشوار الخواجة      0\n",
       "3                             مش عارف ابتدى مذاكره منين      0\n",
       "4     اختصروا الطريق بدلا من اختيار المنصف ثم الانقل...      0\n",
       "...                                                 ...    ...\n",
       "2054  الجمال مبيحتاح اي مكياج لناعم وله خشن جمل الطا...      1\n",
       "2055  نتمني وجود الفنانة رنا سماحة افضل فنانة صاعدة ...      1\n",
       "2056  ولد الهدى فالكاينات ضياء وفم الزمان تبسم وسناء...      2\n",
       "2057                             انت متناقض جدا يا صلاح      0\n",
       "2058     منطقة السيدة زينب ليلة المولد مسجد السيدة زينب      1\n",
       "\n",
       "[2059 rows x 2 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-9390664e-e7fe-4ba2-9bca-840a1176d6ce\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ان الذين يعيشون على الارض ليسوا ملايكة بل بشر ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>كل سنة وانتم طيبين</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>و انتهى مشوار الخواجة</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مش عارف ابتدى مذاكره منين</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اختصروا الطريق بدلا من اختيار المنصف ثم الانقل...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>الجمال مبيحتاح اي مكياج لناعم وله خشن جمل الطا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>نتمني وجود الفنانة رنا سماحة افضل فنانة صاعدة ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>ولد الهدى فالكاينات ضياء وفم الزمان تبسم وسناء...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>انت متناقض جدا يا صلاح</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>منطقة السيدة زينب ليلة المولد مسجد السيدة زينب</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2059 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9390664e-e7fe-4ba2-9bca-840a1176d6ce')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9390664e-e7fe-4ba2-9bca-840a1176d6ce button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9390664e-e7fe-4ba2-9bca-840a1176d6ce');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# Apply label encoding over the labels\n",
    "lable_encoder = preprocessing.LabelEncoder()\n",
    "encoded_labels =lable_encoder.fit_transform(df[\"class\"])\n",
    "df['class']=encoded_labels\n",
    "df"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "nvWAmR5nugwu",
    "outputId": "ebe05a07-30d2-47f5-9cfa-a6ffdbcaae1f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "df['length']=df['tweet'].apply(lambda x:len(x.split(' ')))\n",
    "df['length'].max()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RgOhu_aj4SS",
    "outputId": "df3da832-335c-4f17-a942-6820bcd6b3ac"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Test Split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "RscS77J9ugww"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1298    معناها مش المعني الظاهر معناها نفسها في الجنة ...\n",
       "591                                                     ا\n",
       "1318                                            هاكل اخير\n",
       "1067                                لميس الحديدي تودع عبر\n",
       "29                            انا نهي سنفورة القهوة اديرو\n",
       "                              ...                        \n",
       "1033    صباح اورد من احمد انا بحب سكس انا بحب الزمالك ...\n",
       "674     حياة بالقرب من اله حياة مطمينة محفوفة بالتوفيق...\n",
       "1771                         عليش نسال فيكن معناها ي بصله\n",
       "322                                         شارع الجاردنز\n",
       "1299                          كان نفسي اتولد مخلص ه تعليم\n",
       "Name: tweet, Length: 412, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation=train_test_split(df['tweet'], df['class'], test_size=0.2, random_state=seed)\n",
    "X_validation"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhLxzIXvugwx",
    "outputId": "1085ba06-8206-451f-81ea-9aec30b6d802"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trying some machine learning models"
   ],
   "metadata": {
    "id": "0cs2vHnqBaXF",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF_IDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "kevPnoxdugwy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def tfidf_ngram(n_gram,X_train,X_val):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(n_gram,n_gram))\n",
    "    x_train_vec = vectorizer.fit_transform(X_train)\n",
    "    x_test_vec = vectorizer.transform(X_val)\n",
    "    return x_train_vec,x_test_vec"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "roXYHxrdugwy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Applying tfidf with 1-gram, 2-gram and 3-gram\n",
    "tfidf_1g_transformation_train,tfidf_1g_transformation_validation= tfidf_ngram(1,X_train,X_validation)\n",
    "tfidf_2g_transformation_train,tfidf_2g_transformation_validation= tfidf_ngram(2,X_train,X_validation)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "iuWEPExnugwz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine learning models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "7BYrD0RLugw0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9848208864602307\n",
      "0.3592233009708738\n",
      "0.44383727990285365\n",
      "0.34951456310679613\n",
      "0.9848208864602307\n",
      "0.3616504854368932\n",
      "0.9848208864602307\n",
      "0.3567961165048544\n",
      "0.98421372191864\n",
      "0.3786407766990291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models=[SVC(),XGBClassifier(),RandomForestClassifier(),DecisionTreeClassifier(),LogisticRegression()]\n",
    "for m in models :\n",
    "    m.fit(tfidf_2g_transformation_train,y_train)\n",
    "    print(m.score(tfidf_2g_transformation_train,y_train))\n",
    "    print(m.score(tfidf_2g_transformation_validation,y_validation))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCB9CYrwugw0",
    "outputId": "47b8a203-633d-4f83-c343-2fe875fe6495"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trying to use some pre-trained models from hugging face website "
   ],
   "metadata": {
    "id": "EnB7E1uNBifr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install transformers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "546gZdstugw1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PPa1X-Tugw1",
    "outputId": "82c1ef71-0651-41ea-8c26-0747295232bd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model and Tokenizer initialization"
   ],
   "metadata": {
    "id": "Vn5ecTRICc_J",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "#============= Initialize Arabic Bert =============#\n",
    "#load your pre_trained model with all its weights\n",
    "# model_name= 'aubmindlab/bert-base-arabertv02'\n",
    "model_name='UBC-NLP/MARBERT' #top\n",
    "# model_name='asafaya/bert-base-arabic'\n",
    "# model_name='AraBERTv0.2-Twitter-base'\n",
    "# model_name='aubmindlab/bert-large-arabertv2'\n",
    "# model_name='aubmindlab/bert-base-arabertv02-twitter'\n",
    "# model_name='aubmindlab/bert-large-arabertv02-twitter'\n",
    "# model_name='aubmindlab/aragpt2-base'\n",
    "\n",
    "# model_name='aubmindlab/bert-base-arabertv2'\n",
    "tokenizer =AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "# model=AutoModel.from_pretrained(model_name,output_hidden_states=True)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqHEVmquugw1",
    "outputId": "b85a3f25-9dd1-40c6-b273-56de73263710"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can uncomment ay of the other models to get differnet accuraces"
   ],
   "metadata": {
    "id": "sj6MbwJaB-iz",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  tweet  class  length  \\\n",
       "0     ان الذين يعيشون على الارض ليسوا ملايكة بل بشر ...      2      25   \n",
       "1                                    كل سنة وانتم طيبين      2       4   \n",
       "2                                 و انتهى مشوار الخواجة      0       4   \n",
       "3                             مش عارف ابتدى مذاكره منين      0       5   \n",
       "4     اختصروا الطريق بدلا من اختيار المنصف ثم الانقل...      0      20   \n",
       "...                                                 ...    ...     ...   \n",
       "2054  الجمال مبيحتاح اي مكياج لناعم وله خشن جمل الطا...      1      10   \n",
       "2055  نتمني وجود الفنانة رنا سماحة افضل فنانة صاعدة ...      1      11   \n",
       "2056  ولد الهدى فالكاينات ضياء وفم الزمان تبسم وسناء...      2      16   \n",
       "2057                             انت متناقض جدا يا صلاح      0       5   \n",
       "2058     منطقة السيدة زينب ليلة المولد مسجد السيدة زينب      1       8   \n",
       "\n",
       "                                            bert_tokens  \\\n",
       "0     [[CLS], ان, الذين, يعيشون, على, الارض, ليسوا, ...   \n",
       "1                 [[CLS], كل, سنة, وانتم, طيبين, [SEP]]   \n",
       "2              [[CLS], و, انتهى, مشوار, الخواجة, [SEP]]   \n",
       "3         [[CLS], مش, عارف, ابتدى, مذاكره, منين, [SEP]]   \n",
       "4     [[CLS], اختصر, ##وا, الطريق, بدلا, من, اختيار,...   \n",
       "...                                                 ...   \n",
       "2054  [[CLS], الجمال, مبيح, ##تاح, اي, مكياج, لنا, #...   \n",
       "2055  [[CLS], نتمني, وجود, الفنانة, رنا, سماحة, افضل...   \n",
       "2056  [[CLS], ولد, الهدى, فالك, ##اينات, ضياء, وف, #...   \n",
       "2057         [[CLS], انت, متناقض, جدا, يا, صلاح, [SEP]]   \n",
       "2058  [[CLS], منطقة, السيدة, زينب, ليلة, المولد, مسج...   \n",
       "\n",
       "                                        bert_tokens_ids  \\\n",
       "0     [[CLS], ان, الذين, يعيشون, على, الارض, ليسوا, ...   \n",
       "1                 [[CLS], كل, سنة, وانتم, طيبين, [SEP]]   \n",
       "2              [[CLS], و, انتهى, مشوار, الخواجة, [SEP]]   \n",
       "3         [[CLS], مش, عارف, ابتدى, مذاكره, منين, [SEP]]   \n",
       "4     [[CLS], اختصر, ##وا, الطريق, بدلا, من, اختيار,...   \n",
       "...                                                 ...   \n",
       "2054  [[CLS], الجمال, مبيح, ##تاح, اي, مكياج, لنا, #...   \n",
       "2055  [[CLS], نتمني, وجود, الفنانة, رنا, سماحة, افضل...   \n",
       "2056  [[CLS], ولد, الهدى, فالك, ##اينات, ضياء, وف, #...   \n",
       "2057         [[CLS], انت, متناقض, جدا, يا, صلاح, [SEP]]   \n",
       "2058  [[CLS], منطقة, السيدة, زينب, ليلة, المولد, مسج...   \n",
       "\n",
       "                                                encoded  \n",
       "0     [[tensor(2), tensor(1946), tensor(2468), tenso...  \n",
       "1     [[tensor(2), tensor(2009), tensor(3171), tenso...  \n",
       "2     [[tensor(2), tensor(144), tensor(7609), tensor...  \n",
       "3     [[tensor(2), tensor(2093), tensor(3323), tenso...  \n",
       "4     [[tensor(2), tensor(22181), tensor(1958), tens...  \n",
       "...                                                 ...  \n",
       "2054  [[tensor(2), tensor(4770), tensor(68899), tens...  \n",
       "2055  [[tensor(2), tensor(39939), tensor(3715), tens...  \n",
       "2056  [[tensor(2), tensor(3735), tensor(4880), tenso...  \n",
       "2057  [[tensor(2), tensor(2030), tensor(27008), tens...  \n",
       "2058  [[tensor(2), tensor(5627), tensor(16281), tens...  \n",
       "\n",
       "[2059 rows x 6 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-767b4af9-fb6b-4902-8a93-1254bac8d7a8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>length</th>\n",
       "      <th>bert_tokens</th>\n",
       "      <th>bert_tokens_ids</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ان الذين يعيشون على الارض ليسوا ملايكة بل بشر ...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>[[CLS], ان, الذين, يعيشون, على, الارض, ليسوا, ...</td>\n",
       "      <td>[[CLS], ان, الذين, يعيشون, على, الارض, ليسوا, ...</td>\n",
       "      <td>[[tensor(2), tensor(1946), tensor(2468), tenso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>كل سنة وانتم طيبين</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[[CLS], كل, سنة, وانتم, طيبين, [SEP]]</td>\n",
       "      <td>[[CLS], كل, سنة, وانتم, طيبين, [SEP]]</td>\n",
       "      <td>[[tensor(2), tensor(2009), tensor(3171), tenso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>و انتهى مشوار الخواجة</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[CLS], و, انتهى, مشوار, الخواجة, [SEP]]</td>\n",
       "      <td>[[CLS], و, انتهى, مشوار, الخواجة, [SEP]]</td>\n",
       "      <td>[[tensor(2), tensor(144), tensor(7609), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مش عارف ابتدى مذاكره منين</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[[CLS], مش, عارف, ابتدى, مذاكره, منين, [SEP]]</td>\n",
       "      <td>[[CLS], مش, عارف, ابتدى, مذاكره, منين, [SEP]]</td>\n",
       "      <td>[[tensor(2), tensor(2093), tensor(3323), tenso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اختصروا الطريق بدلا من اختيار المنصف ثم الانقل...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>[[CLS], اختصر, ##وا, الطريق, بدلا, من, اختيار,...</td>\n",
       "      <td>[[CLS], اختصر, ##وا, الطريق, بدلا, من, اختيار,...</td>\n",
       "      <td>[[tensor(2), tensor(22181), tensor(1958), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>الجمال مبيحتاح اي مكياج لناعم وله خشن جمل الطا...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[[CLS], الجمال, مبيح, ##تاح, اي, مكياج, لنا, #...</td>\n",
       "      <td>[[CLS], الجمال, مبيح, ##تاح, اي, مكياج, لنا, #...</td>\n",
       "      <td>[[tensor(2), tensor(4770), tensor(68899), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>نتمني وجود الفنانة رنا سماحة افضل فنانة صاعدة ...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[[CLS], نتمني, وجود, الفنانة, رنا, سماحة, افضل...</td>\n",
       "      <td>[[CLS], نتمني, وجود, الفنانة, رنا, سماحة, افضل...</td>\n",
       "      <td>[[tensor(2), tensor(39939), tensor(3715), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>ولد الهدى فالكاينات ضياء وفم الزمان تبسم وسناء...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>[[CLS], ولد, الهدى, فالك, ##اينات, ضياء, وف, #...</td>\n",
       "      <td>[[CLS], ولد, الهدى, فالك, ##اينات, ضياء, وف, #...</td>\n",
       "      <td>[[tensor(2), tensor(3735), tensor(4880), tenso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>انت متناقض جدا يا صلاح</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[[CLS], انت, متناقض, جدا, يا, صلاح, [SEP]]</td>\n",
       "      <td>[[CLS], انت, متناقض, جدا, يا, صلاح, [SEP]]</td>\n",
       "      <td>[[tensor(2), tensor(2030), tensor(27008), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>منطقة السيدة زينب ليلة المولد مسجد السيدة زينب</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>[[CLS], منطقة, السيدة, زينب, ليلة, المولد, مسج...</td>\n",
       "      <td>[[CLS], منطقة, السيدة, زينب, ليلة, المولد, مسج...</td>\n",
       "      <td>[[tensor(2), tensor(5627), tensor(16281), tens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2059 rows × 6 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-767b4af9-fb6b-4902-8a93-1254bac8d7a8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-767b4af9-fb6b-4902-8a93-1254bac8d7a8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-767b4af9-fb6b-4902-8a93-1254bac8d7a8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "# Tokenize the sentences using bert tokenizer\n",
    "df[\"bert_tokens\"] = df.tweet.apply(lambda x: tokenizer(x).tokens())\n",
    "df[\"bert_tokens_ids\"] = df.tweet.apply(lambda x: tokenizer(x).tokens())\n",
    "df[\"encoded\"] = df.tweet.apply(lambda x: tokenizer.encode_plus(x,return_tensors='pt')['input_ids'])\n",
    "df"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "sc5VRJOCugw2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "d500a758-62b9-4dec-8047-b19c7517d499"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Padding and attention mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "fhb0-jQMugw4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway.\n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = 64\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in df['bert_tokens']]\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "taCZLE63ugw4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, encoded_labels,\n",
    "                                                            random_state=seed, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=seed, test_size=0.1)\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 64\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ip_wd-t9ugw5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set optimizer parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "CEvllsdYugw5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay_rate': 0.01},\n",
    "                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],'weight_decay_rate': 0.0}]\n",
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "# optimizer = optim.BertAdam(optimizer_grouped_parameters,lr=2e-5,warmup=.1)\n",
    "# optimizer = optim.AdamW(optimizer_grouped_parameters,lr=5e-6)\n",
    "optimizer = optim.AdamW(optimizer_grouped_parameters,lr=.00001)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SIutfqrnugw5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "sZZCYaUKugw5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 1.0185067386462772\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:   9%|▉         | 1/11 [00:20<03:21, 20.18s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.6456473214285714\n",
      "Train loss: 0.6970230464277596\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:  18%|█▊        | 2/11 [00:39<02:59, 19.95s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7589285714285714\n",
      "Train loss: 0.45289019777857026\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:  27%|██▋       | 3/11 [00:59<02:37, 19.67s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7254464285714286\n",
      "Train loss: 0.302816536919824\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:  36%|███▋      | 4/11 [01:18<02:16, 19.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7449776785714286\n",
      "Train loss: 0.2339779290145841\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:  45%|████▌     | 5/11 [01:38<01:57, 19.51s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7215401785714286\n",
      "Train loss: 0.1515888745157883\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:  55%|█████▍    | 6/11 [01:57<01:37, 19.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7511160714285714\n",
      "Train loss: 0.09625541007724302\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:  64%|██████▎   | 7/11 [02:17<01:18, 19.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7059151785714286\n",
      "Train loss: 0.07377016281002555\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:  73%|███████▎  | 8/11 [02:36<00:58, 19.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7215401785714286\n",
      "Train loss: 0.06426888524458327\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:  82%|████████▏ | 9/11 [02:55<00:38, 19.46s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7254464285714286\n",
      "Train loss: 0.0689966644577939\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch:  91%|█████████ | 10/11 [03:15<00:19, 19.47s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7667410714285714\n",
      "Train loss: 0.0621599309017946\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch: 100%|██████████| 11/11 [03:34<00:00, 19.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 0.7511160714285714\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import numpy as np\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "t = []\n",
    "\n",
    "# Store our loss and accuracy for plotting\n",
    "\n",
    "train_loss_set = []\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 11\n",
    "\n",
    "# Transfer the model to GPU\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "\n",
    "  # Training\n",
    "\n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "\n",
    "  # Tracking variables\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_labels = b_labels.type(torch.LongTensor)   # casting to long\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids.to(\"cuda\"), token_type_ids=None, attention_mask=b_input_mask.to(\"cuda\"), labels=b_labels.to(\"cuda\"))[\"loss\"]\n",
    "    train_loss_set.append(loss.item())\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "  # Validation\n",
    "\n",
    "  # Put model in evaluation mode to evaluate loss on the validation set\n",
    "  model.eval()\n",
    "\n",
    "  # Tracking variables\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "  # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    # batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_labels = b_labels.type(torch.LongTensor)   # casting to long\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      logits = model(b_input_ids.to(\"cuda\"), token_type_ids=None, attention_mask=b_input_mask.to(\"cuda\"))\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits[\"logits\"].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "  if (eval_accuracy/nb_eval_steps) > 0.77 :\n",
    "    break"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kfOowbxugw6",
    "outputId": "5f51f984-57ff-485b-f6ef-40b4e3b175c8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare testset with the same preprocessing"
   ],
   "metadata": {
    "id": "4onlufXWCqWi",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n"
     ]
    }
   ],
   "source": [
    "#============= Read CSV and apply data preperation =============#\n",
    "df_submit = pd.read_csv(\"Twitter_test.csv\")\n",
    "\n",
    "df_submit[\"tweet\"] = df_submit.tweet.apply(lambda x: data_cleaning(x))\n",
    "df_submit=data_preprocessing(df_submit)\n",
    "\n",
    "df_submit['tweet']=df_submit['tweet'].apply(lambda x: arabert_prep.preprocess(x))\n",
    "\n",
    "# Tokenize the sentences using bert tokenizer\n",
    "df_submit[\"bert_tokens\"] = df_submit.tweet.apply(lambda x: tokenizer(x).tokens())"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "yJ2XSmwSugw6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e867b33c-053f-44b5-ecbf-c6560935b350"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bert_tokens_submit = df_submit[\"bert_tokens\"]"
   ],
   "metadata": {
    "id": "G7iPpop4ytzT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = 64\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids_submit = [tokenizer.convert_tokens_to_ids(x) for x in bert_tokens_submit]\n",
    "# Pad our input tokens\n",
    "input_ids_submit = pad_sequences(input_ids_submit, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Create attention masks\n",
    "attention_masks_submit = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids_submit:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks_submit.append(seq_mask)"
   ],
   "metadata": {
    "id": "Z1vJgu5f0A-3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "inputs_submit = torch.tensor(input_ids_submit)\n",
    "masks_submit = torch.tensor(attention_masks_submit)\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "batch_size = 64\n",
    "submit_data = TensorDataset(inputs_submit, masks_submit)\n",
    "\n",
    "# do not use shuffle, we need the preds to be in same order\n",
    "submit_dataloader = DataLoader(submit_data, batch_size=batch_size)#, shuffle=True)"
   ],
   "metadata": {
    "id": "HUeIG5WD0M9n",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Put the model in an evaluation state\n",
    "model.eval()\n",
    "\n",
    "# Transfer model to GPU\n",
    "model.to(\"cuda\")\n",
    "\n",
    "outputs = []\n",
    "for input, masks in submit_dataloader:\n",
    "  torch.cuda.empty_cache() # empty the gpu memory\n",
    "\n",
    "  # Transfer the batch to gpu\n",
    "  input = input.to('cuda')\n",
    "  masks = masks.to('cuda')\n",
    "\n",
    "  # Run inference on the batch\n",
    "  output = model(input, attention_mask=masks)[\"logits\"]\n",
    "\n",
    "  # Transfer the output to CPU again and convert to numpy\n",
    "  output = output.cpu().detach().numpy()\n",
    "\n",
    "  # Store the output in a list\n",
    "  outputs.append(output)\n",
    "\n",
    "# Concatenate all the lists within the list into one list\n",
    "outputs = [x for y in outputs for x in y]\n",
    "\n",
    "# Inverse transform the label encoding\n",
    "pred_flat = np.argmax(outputs, axis=1).flatten()\n",
    "output_labels = lable_encoder.inverse_transform(pred_flat)"
   ],
   "metadata": {
    "id": "K-32QySM0Qpu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "submission = pd.DataFrame({\"Id\":np.arange(1, len(output_labels)+1), \"class\":output_labels})\n",
    "# save (submission)\n",
    "submission.to_csv(\"submission30.csv\", index=False)"
   ],
   "metadata": {
    "id": "Az3ccyKv0SYu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "NAo2Q_2F06Je",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "Twitter_Classification.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}